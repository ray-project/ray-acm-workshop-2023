{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scaling model training\n",
    "\n",
    "<img src=\"https://technical-training-assets.s3.us-west-2.amazonaws.com/Generic/ray_logo.png\" width=\"20%\" loading=\"lazy\">\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "-   Understand the challenges associated with distributing model training across multiple GPUs.\n",
    "-   Implement the data parallelism design pattern using Ray Datasets.\n",
    "-   Fine-tune a transformer model on an image dataset using Ray Train.\n",
    "-   Evaluate the trained model by performing inference on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up necessary imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from PIL.JpegImagePlugin import JpegImageFile\n",
    "\n",
    "# Set the seed to a fixed value for reproducibility.\n",
    "torch.manual_seed(201)\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Ray runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model components from the HuggingFace Hub\n",
    "\n",
    "From the [Hugging Face Hub](https://huggingface.co/docs/hub/index), retrieve the pretrained SegFormer model by specifying the model name and [label files](https://huggingface.co/datasets/huggingface/label-files/blob/main/ade20k-id2label.json) which map indices to semantic categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load label mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2label, label2id = get_labels()\n",
    "num_labels = len(id2label)\n",
    "\n",
    "print(f\"Total number of labels: {len(id2label)}\")\n",
    "print(f\"Example labels: {list(id2label.values())[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utility function `get_labels` fetches two dictionary mappings from [Hugging Face](https://huggingface.co/datasets/huggingface/label-files/blob/main/ade20k-id2label.json), `id2label` and `label2id`, which are used to convert between numerical and string labels for the 150 available [semantic categories](https://docs.google.com/spreadsheets/d/1se8YEtb2detS7OuPE86fXGyD269pMycAWe2mtKUj2W8/edit#gid=0) of objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load SegFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import SegformerForSemanticSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"nvidia/mit-b0\"                              https://huggingface.co/nvidia/mit-b0\n",
    "# \"nvidia/segformer-b0-finetuned-ade-512-512\"  https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512\n",
    "\n",
    "MODEL_NAME = \"nvidia/mit-b0\"\n",
    "\n",
    "segformer = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    MODEL_NAME, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"Number of model parameters: {segformer.num_parameters()/(10**6):.2f} M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Hugging Face Hub](https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512) makes available many variations on SegFormer. Here, you specify a version finetuned on the MITADE20K (SceneParse150) dataset on images with a 512 x 512 resolution.\n",
    "\n",
    "Note: This \"b0\" model is the smallest, with [other options](https://huggingface.co/nvidia/segformer-b5-finetuned-ade-640-640) ranging up to and including \"b5\". Keep this in mind as something to experiment with when comparing different batch inference architectures later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset from HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from utils import convert_image_to_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SMALL_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "  <strong>SMALL_DATA</strong>: a flag to download a subset (160 images) of the available data. Defaults to True. Set to False (recommended) to work with the full train data (20k images).\n",
    "</div>\n",
    "\n",
    "If you set `SMALL_DATA` to `False`, expect it to take some time (depending on your connection download speed) because you are downloading all test images to your local machine or cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load SceneParse150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = \"scene_parse_150\"\n",
    "\n",
    "# Load data from the Hugging Face datasets repository.\n",
    "if SMALL_DATA:\n",
    "    train_dataset = load_dataset(DATASET_NAME, split=\"train[:160]\")\n",
    "else:\n",
    "    train_dataset = load_dataset(DATASET_NAME, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(convert_image_to_rgb)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample contains three components:\n",
    "* **`image`** \n",
    "    * The PIL image.\n",
    "* **`annotation`**  \n",
    "    * Human annotations of image regions (annotation mask is `None` in testing set).\n",
    "* **`category`**  \n",
    "    * Category of the scene generally (e.g. driveway, voting booth, dairy_outdoor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Display example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import display_example_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try running this multiple times!\n",
    "display_example_images(train_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pause: Switch to Slido to answer a quiz question.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Ray Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "N_BATCHES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get BATCH_SIZE * N_BATCHES randomly shuffled image IDs from the train dataset.\n",
    "image_indices = get_image_indices(dataset=train_dataset, n=BATCH_SIZE * N_BATCHES)\n",
    "\n",
    "# Create a list of tuples (image, label) for the indices sampled from the train dataset.\n",
    "data = [\n",
    "    (train_dataset[i][\"image\"], train_dataset[i][\"annotation\"]) for i in image_indices\n",
    "]\n",
    "\n",
    "# Create a Ray Dataset from the list of images to use in Ray AIR.\n",
    "train_ds = ray.data.from_items(data)\n",
    "train_ds = train_ds.map_batches(\n",
    "    lambda x: pd.DataFrame(x, columns=[\"image\", \"annotation\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display example image\n",
    "train_ds.take(1)[0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display example image\n",
    "train_ds.take(1)[0][\"annotation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create preprocessor for distributed data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import SegformerImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def images_preprocessor(batch):\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    segformer_image_processor = SegformerImageProcessor.from_pretrained(\n",
    "        MODEL_NAME, do_reduce_labels=True\n",
    "    )\n",
    "\n",
    "    # inputs are `transformers.image_processing_utils.BatchFeature`\n",
    "    inputs = segformer_image_processor(\n",
    "        images=list(batch[\"image\"]),\n",
    "        segmentation_maps=list(batch[\"annotation\"]),\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "\n",
    "    return dict(inputs)  # {\"pixel_values\": array, \"labels\": array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Feature extractors](https://huggingface.co/docs/transformers/main_classes/feature_extractor) preprocess input features (e.g. image data) by normalizing, resizing, padding, and converting raw images into the shape expected by SegFormer.\n",
    "\n",
    "The [`reduce_labels`](https://huggingface.co/docs/transformers/model_doc/segformer#segformer) flag ensures that the background of an image (anything that is not explicitly an object) isn't included when computing loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.data.preprocessors import BatchMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_preprocessor = BatchMapper(\n",
    "    fn=images_preprocessor, batch_format=\"pandas\", batch_size=2\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pause: Switch to Slido to answer a quiz question.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run distributed training with SegFormer from HuggingFace you need:\n",
    "\n",
    "* setup batches preprocessor\n",
    "* setup HuggingFace Trainer configuration for all workers\n",
    "* create HuggingFaceTrainer - Ray Train object that handles distributed training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup HuggingFace Trainer per worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainer_init_per_worker(train_dataset, eval_dataset=None, **config):\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    name = \"segformer-finetuned\"\n",
    "\n",
    "    # Setup model\n",
    "    segformer = SegformerForSemanticSegmentation.from_pretrained(\n",
    "        MODEL_NAME, id2label=id2label, label2id=label2id\n",
    "    )\n",
    "\n",
    "    # Setup optimizer and LR scheduler\n",
    "    optimizer = torch.optim.AdamW(params=segformer.parameters(), lr=1e-4)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "        optimizer=optimizer, lr_lambda=lambda x: x\n",
    "    )\n",
    "\n",
    "    # Setup HF Training Arguments\n",
    "    training_args = TrainingArguments(\n",
    "        name,\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        save_total_limit=3,\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        eval_accumulation_steps=2,\n",
    "        log_level=\"error\",\n",
    "        log_level_replica=\"error\",\n",
    "        log_on_each_node=False,\n",
    "        remove_unused_columns=False,\n",
    "        push_to_hub=False,\n",
    "        disable_tqdm=True,  # declutter the output a little\n",
    "        no_cuda=True,\n",
    "    )\n",
    "\n",
    "    # Setup HF Trainer\n",
    "    trainer = Trainer(\n",
    "        model=segformer,\n",
    "        optimizers=(optimizer, lr_scheduler),\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create HuggingFace Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.train.huggingface import HuggingFaceTrainer\n",
    "from ray.air.config import RunConfig, ScalingConfig, CheckpointConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup parameters for the ScalingConfig\n",
    "num_workers = 2\n",
    "use_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Ray's HF Trainer\n",
    "trainer = HuggingFaceTrainer(\n",
    "    trainer_init_per_worker=trainer_init_per_worker,\n",
    "    scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "    datasets={\n",
    "        \"train\": train_ds,\n",
    "    },\n",
    "    run_config=RunConfig(\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=1,\n",
    "            checkpoint_score_attribute=\"loss\",\n",
    "            checkpoint_score_order=\"min\",\n",
    "        ),\n",
    "    ),\n",
    "    preprocessor=batch_preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model training\n",
    "result = trainer.fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pause: Switch to Slido to answer a quiz question.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have successfully gained experience in using Ray Train to fine-tune a vision transformer model for semantic segmentation.In the upcoming module, you will be able to build on this example by conducting a series of hyperparameter tuning experiments using Ray Tune.\n",
    "\n",
    "### Summary\n",
    "\n",
    "-   Distributed model training\n",
    "    -   Training and fine-tuning large neural networks requires a massive amount of compute, so the only solution is to distribute this workload.\n",
    "    -   Data parallelism offers a pattern for sharding a large dataset across multiple machines for training and gradient synchronization.\n",
    "    -   This orchestration and maintenance is challenging, and Ray AIR offers a unified compute solution to scale this workload that integrates well with other stages in the pipeline.\n",
    "-   Fine-tuning Segformer on MITADE20K\n",
    "    -   Data ingest\n",
    "        -   Ray Data can be used to ingest and preprocess training images. These same transformations can be applied during tuning, inference, and serving.\n",
    "    -   Distributed training\n",
    "        -   Ray Train can fine-tune a transformer model, in this case implementing the data parallel design pattern by running PyTorch's [Distributed Data Parallel](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html) as the backend.\n",
    "    -   Evaluation\n",
    "        -   You used Ray AIR's BatchPredictor to assess performance of the fine-tuned model by running inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect with the Ray community\n",
    "\n",
    "You can learn and get more involved with the Ray community of developers and researchers:\n",
    "\n",
    "* [**Ray documentation**](https://docs.ray.io/en/latest)\n",
    "\n",
    "* [**Official Ray site**](https://www.ray.io/)  \n",
    "Browse the ecosystem and use this site as a hub to get the information that you need to get going and building with Ray.\n",
    "\n",
    "* [**Join the community on Slack**](https://forms.gle/9TSdDYUgxYs8SA9e8)  \n",
    "Find friends to discuss your new learnings in our Slack space.\n",
    "\n",
    "* [**Use the discussion board**](https://discuss.ray.io/)  \n",
    "Ask questions, follow topics, and view announcements on this community forum.\n",
    "\n",
    "* [**Join a meetup group**](https://www.meetup.com/Bay-Area-Ray-Meetup/)  \n",
    "Tune in on meet-ups to listen to compelling talks, get to know other users, and meet the team behind Ray.\n",
    "\n",
    "* [**Open an issue**](https://github.com/ray-project/ray/issues/new/choose)  \n",
    "Ray is constantly evolving to improve developer experience. Submit feature requests, bug-reports, and get help via GitHub issues.\n",
    "\n",
    "* [**Become a Ray contributor**](https://docs.ray.io/en/latest/ray-contribute/getting-involved.html)  \n",
    "We welcome community contributions to improve our documentation and Ray framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"https://technical-training-assets.s3.us-west-2.amazonaws.com/Generic/ray_logo.png\" width=\"20%\" loading=\"lazy\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
